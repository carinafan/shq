---
title: "Sea Hero Quest: Qualtrics Data Cleaning"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output: 
  github_document:
    toc: true
---


<!-- ======================================================================= -->


# Set up 

```{r today}
today = "2021-03-18"
```

```{r packages}
library(BBmisc)
library(writexl)
library(magrittr)
library(tidyverse)
```

```{r data}
df.raw = paste0("../data/qualtrics/", today, "-shq-qualtrics-raw.csv") %>% 
  read.csv(stringsAsFactors = FALSE)
```

## Rename variables

```{r rename_variables}
# retrieve column names from raw file exported from Qualtrics
raw_column_name = names(df.raw)

# clean up column names 
clean_column_name = 
	c("start_date", "end_date", "status", "IPaddress", "progress",
	  "duration", "finished", "recorded_date", "responseID",
	  "last_name", "first_name", "recipient_email", "external_reference", 
	  "location_latitude", "location_longitude", "distribution_channel", 
	  "user_language", "consent", "hardware", "recruitment", "recruitment_text",
	  "age", "gender", "gender_text", "retired", "occupation",
	  "edu_years", "edu_degree", "edu_degree_text",
	  "eng_1st_lang", "age_learned_eng", "eng_fluency", "number_lang",
	  "hand", "racialized", "racialized_text", "marginalized", "marginalized_text",
	  "catch_text", "email", "do_not_contact", 
	  "health_colourblind", "health_cholesterol", "health_hypertension",
	  "health_heart", "health_cancer", "health_thyroid", "health_liver",
	  "health_kidney", "health_diabetes", "health_arthritis", "health_neckback", 
	  "health_sleep", "health_obese", "neuro_depression", "neuro_anxiety",
	  "neuro_schiz", "neuro_stroke", "neuro_mci", "neuro_dementia", "neuro_seizures",
	  "neuro_ms", "neuro_tbiMild", "neuro_tbiModSev", "neuro_braintumour", 
	  "neuro_surgery", "neuro_parkinsons", "neuro_other", "neuro_other_text", 
	  "sam_episodic_1", "sam_episodic_2", "sam_episodic_3", "sam_episodic_4", 
	  "sam_episodic_5", "sam_episodic_6", "sam_episodic_7", "sam_episodic_8",
	  "sam_semantic_1", "sam_semantic_2", "sam_semantic_3", 
	  "sam_semantic_4", "sam_semantic_5", "sam_semantic_6",
	  "sam_spatial_1", "sam_spatial_2", "sam_spatial_3", "catch_MC", 
	  "sam_spatial_4", "sam_spatial_5", "sam_spatial_6",
	  "sam_future_1", "sam_future_2", "sam_future_3", 
	  "sam_future_4", "sam_future_5", "sam_future_6",
	  "therapy", "therapy_text", "therapy_date", "therapy_type", "therapy_type_text",
	  "phq_1", "phq_2", "phq_3", "phq_4", "phq_5", 
	  "phq_6", "phq_7", "phq_8", "phq_9", "phq_function",
	  "phq_covid", "covid", "covid_text", 
	  "gift_card", "open_data", "shqID")

# create data frame that matches raw to clean column names	

varnames = cbind(raw_column_name, clean_column_name) %>% 
  as.data.frame(stringsAsFactors = FALSE)

# rename variables

df = df.raw

names(df) = mapValues(x = names(df),
                      from = raw_column_name,
                      to = clean_column_name)
```

```{r}
# change class of all variables from factors to strings
df %<>% mutate_all(as.character)

# remove rows that don't correspond to subject data
df = df[-c(1,2), ]

# add "SHQ" to subject IDs
df$shqID %<>% paste0("SHQ", .)
```


<!-- ======================================================================= -->


# Exclusions

Before any exclusions, there are `r nrow(df)` survey responses. 

```{r exclusions}
# remove variables that don't need to be in cleaned file
df %<>%
	select(-c(start_date, end_date, status, IPaddress, progress, 
	          responseID, last_name, first_name, recipient_email, 
	          external_reference, location_latitude, location_longitude,
	          distribution_channel, user_language, consent))

# create copy of dataframe for cleaning excluded rows later
df.excluded = df
```

## Hardware

```{r exclude_hardware}
exclude.hardware = df %>% 
  filter(hardware == "No")

df %<>% filter(!shqID %in% exclude.hardware$shqID)
```

`r nrow(exclude.hardware)` participants did not have the hardware requirements to play Sea Hero Quest and thus did not complete the study. 

## Duplicate emails

```{r exclude_duplicate}
exclude.email = df %>% 
  filter(email != "", duplicated(email))

df %<>% filter(!shqID %in% exclude.email$shqID)
```

`r nrow(exclude.email)` responses were duplicates emails and thus removed. For duplicates, only the first response was kept. 

## Catch questions

There are 2 "catch" questions to ensure participants are paying attention. 

For the text catch, participants had to answer "What is 2 plus seven?" in a text box. For the multiple choice catch, participants had to select "Strongly Agree". 

```{r exclude_catch}
# text catch
df$catch_text %<>% tolower()

exclude.catchT = df %>% 
  filter(!grepl(pattern = "9|nine", x = catch_text))

# MC catch
exclude.catchM = df %>% 
  filter(catch_MC != "Strongly Agree" | is.na(catch_MC))

# exclude
df %<>% filter(!shqID %in% exclude.catchT |
               !shqID %in% exclude.catchM)
```

After excluding duplicate emails, `r nrow(exclude.catchT)` participants failed the text catch and `r nrow(exclude.catchM)` participants failed the multiple choice catch. 

## Education

```{r exclude_edu}
df$edu_years %<>% as.numeric()

exclude.edu = df %>% 
  filter(edu_years < 9 | edu_years > 26)

df %<>% filter(!shqID %in% exclude.edu$shqID)
```

After excluding duplicate emails and catch fails, `r nrow(exclude.edu)` participants were excluded for having fewer than 9 or greater than 26 years of education. 

## Number of subjects for analysis

After all exclusions, there are `r nrow(df)` subjects left for analysis. 

Check that the number of rows in the clean dataframe plus the number of rows in the excluded dataframe equal the number of rows in the raw data:

```{r exclusion_check}
df.excluded %<>% filter(!shqID %in% df$shqID)
nrow(df.raw) - 2 == nrow(df) + nrow(df.excluded)
```


<!-- ============================================================================= -->


# Demographics

```{r demographics}
# select demographics variables
df.dem = df %>% 
  select(shqID, recorded_date,
         age, gender, gender_text, hand,
         retired, occupation, edu_years, edu_degree, edu_degree_text,
         eng_1st_lang, age_learned_eng, eng_fluency, number_lang, 
         racialized, racialized_text, marginalized, marginalized_text,
         starts_with("health"), starts_with("neuro"), starts_with("therapy"))
```


<!-- ============================================================================= -->


# SAM

```{r sam}
# create new dataframe that only contains SAM items
df.sam = df %>% select(c(shqID, starts_with("sam")))

# replace text in responses with numbers
for (row in 1:nrow(df.sam)) {
  for (col in 2:ncol(df.sam)) {
    switch(df.sam[row, col],
           "Strongly Disagree"           = {df.sam[row, col] = 1},
           "Disagree Somewhat"           = {df.sam[row, col] = 2},
           "Neither Agree nor Disagree"  = {df.sam[row, col] = 3},
           "Agree Somewhat"              = {df.sam[row, col] = 4},
           "Strongly Agree"              = {df.sam[row, col] = 5}
           )
  }
}

# change class of all variables from strings to numeric
df.sam$shqID %<>% as.factor()
df.sam %<>% mutate_if(is.character, as.numeric)

# reverse coding
sam.reverse = c("sam_episodic_1", "sam_episodic_2", 
                "sam_semantic_2", "sam_semantic_5", 
                "sam_spatial_3", "sam_spatial_4", "sam_future_6")

for (i in 1:length(sam.reverse)) {
  df.sam[ , (ncol(df.sam) + 1)] = NA # add an empty column for the reverse coded item
  names(df.sam)[ncol(df.sam)] = paste0(sam.reverse[i], "r") # rename empty column
  colToReverse = which(names(df.sam) == sam.reverse[i]) # retrieve index of item to be reversed
  df.sam[ , ncol(df.sam)] = 6 - df.sam[ , colToReverse] # reverse code the item
  df.sam[ , colToReverse] = NULL # remove the original item score
}

# reorder columns
df.sam = df.sam[ , order(names(df.sam))] %>% 
  select(shqID, everything())

# load script to calculate domain scores
source("sam-shq.R")
```


<!-- ======================================================================= -->


# Run cleaning script on excluded participants

```{r clean_excluded}
# df.excluded %<>% filter(! subjectID %in% df$subjectID)
# 
# # run separate cleaning script
# source("../cleaning/demo-cleaning-excluded.R")
```


<!-- ======================================================================= -->


# Export data

```{r export_varnames}
varnames %>% 
  write.csv(paste0("../data/qualtrics/", today, "-shq-qualtrics-varnames.csv"),
                   row.names = FALSE)
```


```{r export_subjectID}
# export subject IDs and email addresses
subjectID = df %>% select(shqID, email, gift_card, do_not_contact, open_data, recruitment, recruitment_text)

# insert something heree about adding a column as to whether subject made it into clean data and can be compensated

subjectID %>% 
  write_xlsx(paste0("../data/qualtrics/", today, "-shq-qualtrics-subjectID.xlsx"))
```

```{r export_data}
# df$email = NULL
```



<!-- ======================================================================= -->


# Session info

```{r session_info, include = TRUE}
sessionInfo()
```